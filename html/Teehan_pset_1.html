
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>Teehan_pset_1</title><meta name="generator" content="MATLAB 9.3"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2018-01-27"><meta name="DC.source" content="Teehan_pset_1.m"><style type="text/css">
html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,font,img,ins,kbd,q,s,samp,small,strike,strong,sub,sup,tt,var,b,u,i,center,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td{margin:0;padding:0;border:0;outline:0;font-size:100%;vertical-align:baseline;background:transparent}body{line-height:1}ol,ul{list-style:none}blockquote,q{quotes:none}blockquote:before,blockquote:after,q:before,q:after{content:'';content:none}:focus{outine:0}ins{text-decoration:none}del{text-decoration:line-through}table{border-collapse:collapse;border-spacing:0}

html { min-height:100%; margin-bottom:1px; }
html body { height:100%; margin:0px; font-family:Arial, Helvetica, sans-serif; font-size:10px; color:#000; line-height:140%; background:#fff none; overflow-y:scroll; }
html body td { vertical-align:top; text-align:left; }

h1 { padding:0px; margin:0px 0px 25px; font-family:Arial, Helvetica, sans-serif; font-size:1.5em; color:#d55000; line-height:100%; font-weight:normal; }
h2 { padding:0px; margin:0px 0px 8px; font-family:Arial, Helvetica, sans-serif; font-size:1.2em; color:#000; font-weight:bold; line-height:140%; border-bottom:1px solid #d6d4d4; display:block; }
h3 { padding:0px; margin:0px 0px 5px; font-family:Arial, Helvetica, sans-serif; font-size:1.1em; color:#000; font-weight:bold; line-height:140%; }

a { color:#005fce; text-decoration:none; }
a:hover { color:#005fce; text-decoration:underline; }
a:visited { color:#004aa0; text-decoration:none; }

p { padding:0px; margin:0px 0px 20px; }
img { padding:0px; margin:0px 0px 20px; border:none; }
p img, pre img, tt img, li img, h1 img, h2 img { margin-bottom:0px; } 

ul { padding:0px; margin:0px 0px 20px 23px; list-style:square; }
ul li { padding:0px; margin:0px 0px 7px 0px; }
ul li ul { padding:5px 0px 0px; margin:0px 0px 7px 23px; }
ul li ol li { list-style:decimal; }
ol { padding:0px; margin:0px 0px 20px 0px; list-style:decimal; }
ol li { padding:0px; margin:0px 0px 7px 23px; list-style-type:decimal; }
ol li ol { padding:5px 0px 0px; margin:0px 0px 7px 0px; }
ol li ol li { list-style-type:lower-alpha; }
ol li ul { padding-top:7px; }
ol li ul li { list-style:square; }

.content { font-size:1.2em; line-height:140%; padding: 20px; }

pre, code { font-size:12px; }
tt { font-size: 1.2em; }
pre { margin:0px 0px 20px; }
pre.codeinput { padding:10px; border:1px solid #d3d3d3; background:#f7f7f7; }
pre.codeoutput { padding:10px 11px; margin:0px 0px 20px; color:#4c4c4c; }
pre.error { color:red; }

@media print { pre.codeinput, pre.codeoutput { word-wrap:break-word; width:100%; } }

span.keyword { color:#0000FF }
span.comment { color:#228B22 }
span.string { color:#A020F0 }
span.untermstring { color:#B20000 }
span.syscmd { color:#B28C00 }

.footer { width:auto; padding:10px 0px; margin:25px 0px 0px; border-top:1px dotted #878787; font-size:0.8em; line-height:140%; font-style:italic; color:#878787; text-align:left; float:none; }
.footer p { margin:0px; }
.footer a { color:#878787; }
.footer a:hover { color:#878787; text-decoration:underline; }
.footer a:visited { color:#878787; }

table th { padding:7px 5px; text-align:left; vertical-align:middle; border: 1px solid #d6d4d4; font-weight:bold; }
table td { padding:7px 5px; text-align:left; vertical-align:top; border:1px solid #d6d4d4; }





  </style></head><body><div class="content"><h2>Contents</h2><div><ul><li><a href="#2">1.1 &amp; 1.2</a></li><li><a href="#3">2.1</a></li><li><a href="#4">2.2</a></li><li><a href="#6">3.1a</a></li><li><a href="#7">3.1b</a></li><li><a href="#8">3.1c</a></li><li><a href="#9">3.1d</a></li><li><a href="#10">3.2</a></li><li><a href="#11">3.2a</a></li><li><a href="#12">3.2b</a></li><li><a href="#13">3.2b</a></li></ul></div><pre class="codeinput">load(<span class="string">'mtSpikeTimes.mat'</span>);
</pre><h2 id="2">1.1 &amp; 1.2</h2><pre class="codeinput">figure; hold <span class="string">on</span>
subplot(8,1,[1 2])
<span class="keyword">for</span> i = 1:length(mtSpikeTimes)
    trial = mtSpikeTimes{i};

    <span class="keyword">for</span> iid = 1:length(trial)
        hold <span class="string">on</span>
        spkx=[trial(iid) trial(iid)];
        spky = [0 1] + i;
        line(spkx,spky,<span class="string">'LineWidth'</span>,1);
    <span class="keyword">end</span>
<span class="keyword">end</span>
xlabel(<span class="string">'Time (sec)'</span>)
title(<span class="string">'Raster Plot'</span>)

subplot(8,1,[4 5])
PlotPSTH(mtSpikeTimes, 10)
title(<span class="string">'PSTH 10 bins'</span>)

subplot(8,1,[7 8])
PlotPSTH(mtSpikeTimes, 20)
title(<span class="string">'PSTH 20 bins'</span>)

fprintf(<span class="string">'As the number of bins increases, the "resolution" on the graph'</span>)
fprintf(<span class="string">' gets finer, which may mean the curve gets smoother if you start \n'</span>)
fprintf(<span class="string">' with too few bins, but may mean it gets more jagged if you go too'</span>)
fprintf(<span class="string">' high.'</span>)
</pre><pre class="codeoutput">As the number of bins increases, the "resolution" on the graph gets finer, which may mean the curve gets smoother if you start 
 with too few bins, but may mean it gets more jagged if you go too high.</pre><img vspace="5" hspace="5" src="Teehan_pset_1_01.png" alt=""> <h2 id="3">2.1</h2><pre class="codeinput">[mean_val, std_val, coef_var, fano, d] = GetStats(mtSpikeTimes, .03);
fprintf(<span class="string">'For 30ms: \n'</span>)
fprintf(<span class="string">'The mean firing rate is %4.5f \n'</span>, mean_val)
fprintf(<span class="string">'The standard deviation of the firing rate is %4.5f \n'</span>, std_val)
fprintf(<span class="string">'The coefficient of variation is %4.5f \n'</span>, coef_var)
fprintf(<span class="string">'The Fano Factor of the counts is: %4.5f \n'</span>, fano)

clear <span class="string">mean_val</span> <span class="string">std_val</span> <span class="string">coef_var</span> <span class="string">fano</span> <span class="string">d</span>

[mean_val, std_val, coef_var, fano, d] = GetStats(mtSpikeTimes, .3);
fprintf(<span class="string">'For 300ms: \n'</span>)
fprintf(<span class="string">'The mean firing rate is %4.5f \n'</span>, mean_val)
fprintf(<span class="string">'The standard deviation of the firing rate is %4.5f \n'</span>, std_val)
fprintf(<span class="string">'The coefficient of variation is %4.5f \n'</span>, coef_var)
fprintf(<span class="string">'The Fano Factor of the counts is: %4.5f \n'</span>, fano)
</pre><pre class="codeoutput">For 30ms: 
The mean firing rate is 81.52174 
The standard deviation of the firing rate is 40.29766 
The coefficient of variation is 0.49432 
The Fano Factor of the counts is: 0.59760 
For 300ms: 
The mean firing rate is 35.19928 
The standard deviation of the firing rate is 15.49300 
The coefficient of variation is 0.44015 
The Fano Factor of the counts is: 2.04578 
</pre><h2 id="4">2.2</h2><p>ISI histogram</p><pre class="codeinput">figure; hold <span class="string">on</span>

<span class="comment">%normalize histogram</span>
[nums, cents] = hist(d, 100);
nums = nums / nums(1);
bar(cents, nums);


<span class="comment">% fit exponential curve</span>
x = linspace(0, .5, 100);
y = exp((-x)*mean_val);
plot(x,y, <span class="string">'color'</span>, <span class="string">'red'</span>);

fprintf(<span class="string">'The curves match fairly well, the histogram appears to be'</span>)
fprintf(<span class="string">' following the exponential curve I added to the graph to '</span>)
fprintf(<span class="string">' illustrate a Poisson distribution.'</span>)
</pre><pre class="codeoutput">The curves match fairly well, the histogram appears to be following the exponential curve I added to the graph to  illustrate a Poisson distribution.</pre><img vspace="5" hspace="5" src="Teehan_pset_1_02.png" alt=""> <pre class="codeinput">load(<span class="string">'S1_Ideal_Observer_Analysis.mat'</span>);
</pre><h2 id="6">3.1a</h2><pre class="codeinput"><span class="comment">% preparing the data</span>
amplitudes = Data.stimuli{1}(:,2,:);
directions = Data.stimuli{1}(:,3,:);

new_directions = [];
neuron_1 = {};
neuron_2 = {};
<span class="keyword">for</span> i = 1:length(Data.spikes{1})
    <span class="keyword">if</span> amplitudes(i) == 700
        neuron_1{length(neuron_1) + 1} = Data.spikes{1}{i};
        neuron_2{length(neuron_2) + 1} = Data.spikes{2}{i};
        new_directions = [new_directions directions(i)];
    <span class="keyword">end</span>
<span class="keyword">end</span>

<span class="comment">% make a colormap</span>
colormap = GetColormap(directions)



figure; hold <span class="string">on</span>


subplot(1,2,1)
RasterByDirection(new_directions, neuron_1, colormap)
title(<span class="string">'Neuron 1'</span>);


subplot(1,2,2)
RasterByDirection(new_directions, neuron_2, colormap)
title(<span class="string">'Neuron 2'</span>);
</pre><pre class="codeoutput">
colormap = 

  Map with properties:

        Count: 16
      KeyType: double
    ValueType: any

</pre><img vspace="5" hspace="5" src="Teehan_pset_1_03.png" alt=""> <h2 id="7">3.1b</h2><pre class="codeinput">figure; hold <span class="string">on</span>

<span class="comment">% sort trials by direction</span>

trial_by_direction_1 = SortTrialsByDirection(new_directions, neuron_1);
trial_by_direction_2 = SortTrialsByDirection(new_directions, neuron_2);

<span class="comment">% now get the avg firing rates for each direction</span>

<span class="comment">% now plot and get the preferred direction and firing rates sorted</span>
<span class="comment">% by direction</span>
subplot(2,1,1)
[preferred_1, rates_by_direction_1] = <span class="keyword">...</span>
    GetFiringRatesAndAvg(trial_by_direction_1);
title(<span class="string">'Neuron 1'</span>)

subplot(2,1,2)
[preferred_2, rates_by_direction_2] = <span class="keyword">...</span>
    GetFiringRatesAndAvg(trial_by_direction_2);
title(<span class="string">'Neuron 2'</span>)
</pre><img vspace="5" hspace="5" src="Teehan_pset_1_04.png" alt=""> <h2 id="8">3.1c</h2><pre class="codeinput">figure; hold <span class="string">on</span>

subplot(2,1,1)
threshold_1 = PlotNeurometric(rates_by_direction_1, preferred_1, 1000)
title(<span class="string">'Neuron 1'</span>);

subplot(2,1,2)
threshold_2 = PlotNeurometric(rates_by_direction_2, preferred_2, 1000)
title(<span class="string">'Neuron 2'</span>)


fprintf(<span class="string">'The threshold for both is around 22.5 \n'</span>)
fprintf(<span class="string">'The second neuron is abnormal because it dips significantly'</span>)
fprintf(<span class="string">' below the threshold after it reaches it'</span>)
</pre><pre class="codeoutput">
threshold_1 =

   22.5000


threshold_2 =

   180

The threshold for both is around 22.5 
The second neuron is abnormal because it dips significantly below the threshold after it reaches it</pre><img vspace="5" hspace="5" src="Teehan_pset_1_05.png" alt=""> <h2 id="9">3.1d</h2><pre class="codeinput">[preferred_1, new_rates_1] = ResortByDirection(rates_by_direction_1);
[preferred_2, new_rates_2] = ResortByDirection(rates_by_direction_2);

figure; hold <span class="string">on</span>

subplot(2,1,1)
threshold_1 = PlotNeurometric(new_rates_1, preferred_1, 10000)

subplot(2,1,2)
threshold_2 = PlotNeurometric(new_rates_2, preferred_2, 10000)

fprintf(<span class="string">'The thresholds are: \n'</span>)
fprintf(<span class="string">'Neuron 1: %2.1f \n'</span>, threshold_1)
fprintf(<span class="string">'Neuron 2: %2.4f \n'</span>, threshold_2)
</pre><pre class="codeoutput">
keys =

  1&times;16 cell array

  Columns 1 through 6

    {[0]}    {[22.5000]}    {[45]}    {[67.5000]}    {[90]}    {[112.5000]}

  Columns 7 through 11

    {[135]}    {[157.5000]}    {[180]}    {[202.5000]}    {[225]}

  Columns 12 through 16

    {[247.5000]}    {[270]}    {[292.5000]}    {[315]}    {[337.5000]}


final =

  Columns 1 through 7

    6.6769         0    9.2997         0         0    3.8992    3.0768

  Columns 8 through 10

    3.3770         0    9.8695


new_k =

     0


final =

  Columns 1 through 7

    5.5016    7.7888         0         0   11.8659   12.7486   10.2958

  Columns 8 through 10

   15.0267    8.8984   10.4084


new_k =

   22.5000


final =

  Columns 1 through 7

         0         0         0         0    2.2985   13.8571   15.7323

  Columns 8 through 10

   15.2872   11.8450   10.5363


new_k =

    45


final =

  Columns 1 through 7

    5.5785         0         0         0         0   23.4129   21.5399

  Columns 8 through 10

   18.2482   15.3429   16.8993


new_k =

   67.5000


final =

  Columns 1 through 7

         0         0         0         0         0   20.2543   22.7487

  Columns 8 through 10

   19.4666   16.8271   17.2533


new_k =

    90


final =

  Columns 1 through 7

         0         0    7.7882         0         0   11.6966   15.3860

  Columns 8 through 10

   14.1981   17.3656   20.7541


new_k =

  112.5000


final =

  Columns 1 through 7

         0         0         0         0         0   17.8683   12.1507

  Columns 8 through 10

    9.1008    8.8556   11.7675


new_k =

   135


final =

  Columns 1 through 7

    3.2568    3.6082         0         0         0    5.1395    5.3350

  Columns 8 through 10

    3.3175         0    6.4742


new_k =

  157.5000


keys =

  1&times;16 cell array

  Columns 1 through 6

    {[0]}    {[22.5000]}    {[45]}    {[67.5000]}    {[90]}    {[112.5000]}

  Columns 7 through 11

    {[135]}    {[157.5000]}    {[180]}    {[202.5000]}    {[225]}

  Columns 12 through 16

    {[247.5000]}    {[270]}    {[292.5000]}    {[315]}    {[337.5000]}


final =

  Columns 1 through 7

   11.3685   20.8203   10.6967   25.3807   16.7448         0   29.3836

  Columns 8 through 10

   29.8196   34.0368   28.0781


new_k =

     0


final =

  Columns 1 through 7

    9.9072   10.0791   23.4412   14.7536   14.9083    6.4742   23.3618

  Columns 8 through 10

   35.1808    7.0279         0


new_k =

   22.5000


final =

  Columns 1 through 7

   31.8167   40.5640   42.7137   35.9783   36.7070   47.5243   46.2718

  Columns 8 through 10

   48.3092   43.5686   37.7190


new_k =

    45


final =

  Columns 1 through 7

   49.8079   57.0268   52.3110   52.1415   52.0544   55.2396   64.1473

  Columns 8 through 10

   53.9924   60.1009   50.7717


new_k =

   67.5000


final =

  Columns 1 through 7

   44.6246   40.1023   55.5329   46.5202   52.5920   48.1341   54.9975

  Columns 8 through 10

   45.5944   58.2961   51.5272


new_k =

    90


final =

  Columns 1 through 7

    8.1753   21.4696   19.0803   16.4384   23.9866   19.0840   19.0180

  Columns 8 through 10

   16.1823   23.3218   28.8378


new_k =

  112.5000


final =

  Columns 1 through 7

         0   13.1518         0    7.7253   19.7239    9.5566   11.5680

  Columns 8 through 10

   12.4937   11.1037   13.4898


new_k =

   135


final =

  Columns 1 through 7

   65.1466   26.6525   16.2999   28.1294   14.0786   17.6710   44.9993

  Columns 8 through 10

         0   12.8584   30.5763


new_k =

  157.5000


threshold_1 =

    90


threshold_2 =

   22.5000

The thresholds are: 
Neuron 1: 90.0 
Neuron 2: 22.5000 
</pre><img vspace="5" hspace="5" src="Teehan_pset_1_06.png" alt=""> <h2 id="10">3.2</h2><pre class="codeinput">load(<span class="string">'choiceData.mat'</span>)
</pre><h2 id="11">3.2a</h2><pre class="codeinput">behaviors_1 = choiceData.behavioralReport{1};
behaviors_2 = choiceData.behavioralReport{2};
neuron_1 = choiceData.spikes{1};
neuron_2 = choiceData.spikes{2};

figure;hold <span class="string">on</span>

RasterByBehavior(neuron_1, behaviors_1, 1)
title(<span class="string">'Neuron 1/ Behavior 1'</span>)

figure; hold <span class="string">on</span>
RasterByBehavior(neuron_1, behaviors_1, 2)
title(<span class="string">'Neuron 1/ Behavior 2'</span>)

figure; hold <span class="string">on</span>
RasterByBehavior(neuron_2, behaviors_2, 1)
title(<span class="string">'Neuron 2/ Behavior 1'</span>)

figure; hold <span class="string">on</span>
RasterByBehavior(neuron_2, behaviors_2, 2)
title(<span class="string">'Neuron 2/ Behavior 2'</span>)
</pre><img vspace="5" hspace="5" src="Teehan_pset_1_07.png" alt=""> <img vspace="5" hspace="5" src="Teehan_pset_1_08.png" alt=""> <img vspace="5" hspace="5" src="Teehan_pset_1_09.png" alt=""> <img vspace="5" hspace="5" src="Teehan_pset_1_10.png" alt=""> <h2 id="12">3.2b</h2><pre class="codeinput">p_1 = ChoiceProbabilities(neuron_1, behaviors_1, 1000);
p_2 = ChoiceProbabilities(neuron_2, behaviors_2, 1000);
</pre><pre class="codeoutput">
samp =

    0.0030
    0.0680
    0.0710
    0.0770
    0.0810
    0.0870
    0.0900
    0.0990
    0.1060
    0.1160
    0.1190
    0.1220
    0.1280
    0.1320
    0.1390
    0.1510
    0.1600
    0.1710
    0.1890
    0.1930
    0.2210
    0.2250
    0.2480
    0.2830
    0.2880
    0.2900
    0.3260
    0.3520
    0.3580
    0.3610
    0.3690
    0.4210
    0.4280
    0.4430
    0.4490
    0.4560
    0.4880
    0.4930
    0.5110
    0.5210
    0.5300
    0.5430
    0.5580
    0.6360
    0.6470


samp =

    0.0440
    0.0460
    0.0490
    0.0530
    0.0550
    0.0630
    0.0790
    0.0830
    0.0950
    0.1200
    0.1240
    0.1470
    0.1550
    0.1680
    0.1880
    0.1920
    0.1950
    0.2030
    0.2260
    0.2320
    0.2340
    0.2440
    0.2620
    0.2790
    0.2830
    0.2900
    0.2940
    0.2970
    0.3030
    0.3200
    0.3400
    0.3650
    0.3910
    0.4010
    0.4070
    0.4120
    0.4190
    0.4370
    0.4590
    0.4670
    0.4720
    0.4810
    0.4880
    0.5020
    0.5250
    0.5410
    0.5480
    0.5550
    0.6110
    0.6170
    0.6280
    0.6430
    0.6500


samp =

    0.0020
    0.0490
    0.0550
    0.0580
    0.0690
    0.0860
    0.0990
    0.1040
    0.1110
    0.1160
    0.1250
    0.1510
    0.1580
    0.1680
    0.1750
    0.1960
    0.2010
    0.2530
    0.2910
    0.3100
    0.3190
    0.3300
    0.3460
    0.3480
    0.3630
    0.3690
    0.3850
    0.3950
    0.4050
    0.4180
    0.4210
    0.4270
    0.4370
    0.4410
    0.4480
    0.4900
    0.5000
    0.5160
    0.5310
    0.5600
    0.5910


samp =

    0.0220
    0.0300
    0.0710
    0.0800
    0.0840
    0.0870
    0.0900
    0.0920
    0.1050
    0.1350
    0.1410
    0.1480
    0.1530
    0.1590
    0.1670
    0.1730
    0.1850
    0.1920
    0.1980
    0.2040
    0.2120
    0.2220
    0.2250
    0.2520
    0.2680
    0.2700
    0.2810
    0.2880
    0.2970
    0.2990
    0.3090
    0.3230
    0.3530
    0.3580
    0.3630
    0.3710
    0.3770
    0.4080
    0.4190
    0.4300
    0.4410
    0.4740
    0.5590
    0.5800
    0.5860
    0.6000


samp =

    0.0070
    0.0250
    0.0310
    0.0390
    0.0490
    0.0550
    0.0620
    0.0690
    0.0760
    0.0800
    0.0840
    0.0900
    0.0920
    0.0970
    0.1040
    0.1110
    0.1140
    0.1210
    0.1280
    0.1380
    0.1400
    0.1480
    0.1520
    0.1550
    0.1590
    0.1620
    0.1640
    0.1660
    0.1760
    0.1820
    0.1880
    0.1920
    0.1950
    0.2040
    0.2140
    0.2210
    0.2300
    0.2330
    0.2380
    0.2500
    0.2600
    0.2690
    0.2710
    0.2750
    0.2860
    0.3040
    0.3180
    0.3250
    0.3330
    0.3510
    0.3970
    0.4290
    0.4420
    0.4520
    0.5410
    0.5450
    0.5510
    0.5580
    0.6080
    0.6100


samp =

    0.0030
    0.0080
    0.0150
    0.0210
    0.0250
    0.0290
    0.0310
    0.0460
    0.0530
    0.0810
    0.0830
    0.0880
    0.0950
    0.1010
    0.1140
    0.1230
    0.1410
    0.1520
    0.1590
    0.1630
    0.1830
    0.1920
    0.2050
    0.2090
    0.2260
    0.2590
    0.2620
    0.2790
    0.3030
    0.3220
    0.3390
    0.3950
    0.4020
    0.4100
    0.4160
    0.4510
    0.4540
    0.4600
    0.4790
    0.4900
    0.4950
    0.5080
    0.5750
    0.5800
    0.5840
    0.5880
    0.5980
    0.6260
    0.6280
    0.6410
    0.6490


samp =

    0.0020
    0.0070
    0.0650
    0.0680
    0.1180
    0.1290
    0.1350
    0.1390
    0.1470
    0.1510
    0.1800
    0.1840
    0.1880
    0.1910
    0.1990
    0.2070
    0.2300
    0.2420
    0.2460
    0.2530
    0.2660
    0.2690
    0.2750
    0.2780
    0.2920
    0.3140
    0.3170
    0.3210
    0.3240
    0.3290
    0.3410
    0.3460
    0.3530
    0.3600
    0.3680
    0.3760
    0.3910
    0.3950
    0.4080
    0.4270
    0.4310
    0.4410
    0.4580
    0.4700
    0.4780
    0.4890
    0.4920
    0.4960
    0.5050
    0.5110
    0.5820
    0.5890
    0.6120


samp =

    0.0120
    0.0170
    0.0210
    0.0270
    0.0800
    0.0880
    0.1170
    0.1310
    0.1490
    0.1550
    0.1600
    0.1670
    0.1860
    0.1940
    0.2020
    0.2060
    0.2330
    0.3260
    0.3540
    0.3970
    0.4110
    0.4260
    0.4640
    0.4690
    0.4780
    0.4830
    0.5190
    0.5310
    0.5390
    0.5630
    0.5720
    0.6080
    0.6250
    0.6310


samp =

    0.0040
    0.0080
    0.0880
    0.0930
    0.0960
    0.1000
    0.1090
    0.1140
    0.1220
    0.1540
    0.1740
    0.1800
    0.2220
    0.2340
    0.3110
    0.3150
    0.3230
    0.3870
    0.3890
    0.3960
    0.3990
    0.4040
    0.4120
    0.4460
    0.4540
    0.4940
    0.5040
    0.5610
    0.5750


samp =

         0
    0.0060
    0.0090
    0.0200
    0.0240
    0.0370
    0.0550
    0.0650
    0.0680
    0.0750
    0.0820
    0.0860
    0.1040
    0.1100
    0.1140
    0.1160
    0.1210
    0.1240
    0.1400
    0.1500
    0.1630
    0.1690
    0.1760
    0.1790
    0.1860
    0.2170
    0.2240
    0.2310
    0.2390
    0.2460
    0.2960
    0.3120
    0.3200
    0.3610
    0.3640
    0.4030
    0.4430
    0.4560
    0.4660
    0.5470
    0.5580
    0.6070
    0.6190
    0.6370


samp =

    0.0960
    0.1630
    0.1880
    0.1910
    0.2800
    0.4280


samp =

    0.0010
    0.0070
    0.0690
    0.0720
    0.0780
    0.0800
    0.0820
    0.0850
    0.0940
    0.1080
    0.1210
    0.1230
    0.1270
    0.1310
    0.1340
    0.1420
    0.1460
    0.1520
    0.1540
    0.1600
    0.1640
    0.1670
    0.1700
    0.1790
    0.1820
    0.1900
    0.2010
    0.2120
    0.2190
    0.2240
    0.2280
    0.2310
    0.2360
    0.2380
    0.2460
    0.2490
    0.2560
    0.2630
    0.2700
    0.2720
    0.2860
    0.2900
    0.2930
    0.3000
    0.3080
    0.3140
    0.3300
    0.3330
    0.3380
    0.3430
    0.3470
    0.3560
    0.3590
    0.3710
    0.3900
    0.4100
    0.4180
    0.4290
    0.4320
    0.4370
    0.4420
    0.4740
    0.4800
    0.4970
    0.5020
    0.5070
    0.5200
    0.5520
    0.5550
    0.5670
    0.5710
    0.5850
    0.5950
    0.6290
    0.6350


samp =

    0.0030
    0.0260
    0.0320
    0.0410
    0.0610
    0.0660
    0.0750
    0.0810
    0.0850
    0.0960
    0.1060
    0.1160
    0.1240
    0.1270
    0.1340
    0.1390
    0.1440
    0.1490
    0.1530
    0.1560
    0.1670
    0.1710
    0.1840
    0.1910
    0.1930
    0.1970
    0.2000
    0.2040
    0.2070
    0.2160
    0.2180
    0.2410
    0.2440
    0.2470
    0.2600
    0.2730
    0.2820
    0.3090
    0.3200
    0.3260
    0.3430
    0.3480
    0.3530
    0.3550
    0.3940
    0.4060
    0.4140
    0.4580
    0.4610
    0.4670
    0.4820
    0.5300
    0.5430
    0.5530
    0.5680
    0.6290
    0.6470


samp =

    0.0830
    0.0920
    0.0980
    0.1010
    0.1060
    0.1120
    0.1140
    0.1160
    0.1220
    0.1260
    0.1320
    0.1490
    0.1520
    0.1600
    0.1680
    0.1800
    0.2210
    0.2440
    0.2980
    0.3120
    0.4020
    0.4120
    0.4270
    0.4460
    0.4900
    0.4950
    0.6000
    0.6340


samp =

    0.0260
    0.0280
    0.0320
    0.0390
    0.0440
    0.0500
    0.0770
    0.0870
    0.0930
    0.1030
    0.1110
    0.1360
    0.1380
    0.1480
    0.1510
    0.1580
    0.1640
    0.1690
    0.1750
    0.1820
    0.1940
    0.1980
    0.2100
    0.2160
    0.2210
    0.2390
    0.2490
    0.2530
    0.2620
    0.2880
    0.2910
    0.2960
    0.3010
    0.3120
    0.3550
    0.3570
    0.3600
    0.4060
    0.4600
    0.4820
    0.4890
    0.4970
    0.5630
    0.5700
    0.5800
    0.5910
    0.6350
    0.6380
    0.6410


samp =

    0.0660
    0.0730
    0.0760
    0.0790
    0.0850
    0.0950
    0.1000
    0.1050
    0.1130
    0.1220
    0.1480
    0.1510
    0.1620
    0.1800
    0.1830
    0.1940
    0.1980
    0.2060
    0.2600
    0.2660
    0.2920
    0.3380
    0.4110
    0.5080
    0.5490
    0.5730
    0.6370
    0.6440
    0.6500


samp =

    0.0030
    0.0200
    0.0250
    0.0280
    0.0370
    0.0400
    0.0760
    0.0860
    0.0890
    0.1000
    0.1140
    0.1290
    0.1370
    0.1430
    0.1520
    0.2080
    0.2120
    0.2150
    0.2220
    0.2360
    0.2890
    0.2910
    0.2930
    0.3130
    0.3400
    0.3660
    0.3770
    0.3880
    0.4300
    0.4360
    0.4410
    0.4990
    0.5100
    0.5340
    0.5960
    0.6040
    0.6480


samp =

    0.0070
    0.0120
    0.0210
    0.0340
    0.0850
    0.0880
    0.0940
    0.1000
    0.1040
    0.1070
    0.1220
    0.1610
    0.1690
    0.1710
    0.1990
    0.2470
    0.2490
    0.3070
    0.3280
    0.3310
    0.3420
    0.4180
    0.4220
    0.4320
    0.4900
    0.4930
    0.4990
    0.5770
    0.5820
    0.5930
    0.5990
    0.6030
    0.6150
    0.6190


samp =

    0.0020
    0.0060
    0.0140
    0.0180
    0.0450
    0.0520
    0.0740
    0.0780
    0.0970
    0.1110
    0.1150
    0.1230
    0.1340
    0.1450
    0.1480
    0.1590
    0.1700
    0.1730
    0.1880
    0.1970
    0.2080
    0.2120
    0.2260
    0.2300
    0.2700
    0.2790
    0.2980
    0.3230
    0.3760
    0.3800
    0.3880
    0.4590
    0.5660
    0.5820
    0.5890


samp =

    0.0200
    0.0240
    0.0270
    0.0300
    0.0400
    0.0750
    0.0860
    0.0880
    0.0910
    0.0980
    0.1540
    0.1610
    0.1750
    0.2110
    0.2150
    0.2240
    0.2280
    0.2340
    0.2420
    0.2500
    0.2530
    0.2570
    0.2600
    0.2980
    0.3000
    0.3050
    0.3140
    0.3180
    0.3220
    0.3280
    0.3390
    0.3430
    0.3600
    0.3640
    0.3680
    0.3990
    0.4020
    0.4090
    0.4160
    0.4240
    0.4410
    0.4800
    0.4900
    0.5320
    0.5380
    0.5480
    0.5550
    0.5720
    0.5820
    0.5990
    0.6050
    0.6100
    0.6300


samp =

    0.0250
    0.0670
    0.0750
    0.1210
    0.1270
    0.1350
    0.1440
    0.1540
    0.1890
    0.1940
    0.1980
    0.2000
    0.2310
    0.2380
    0.2410
    0.2740
    0.2800
    0.2830
    0.3000
    0.3020
    0.3070
    0.3440
    0.3500
    0.4280
    0.4320
    0.4410
    0.5000
    0.5240
    0.5710
    0.5850
    0.5870
    0.5930
    0.5980
    0.6290
    0.6340


samp =

    0.0270
    0.0340
    0.0380
    0.0450
    0.0780
    0.0830
    0.0940
    0.1070
    0.1110
    0.1160
    0.1180
    0.1280
    0.1330
    0.1360
    0.1510
    0.1640
    0.1880
    0.1960
    0.2020
    0.2070
    0.2220
    0.2420
    0.2500
    0.2710
    0.2850
    0.2880
    0.3000
    0.3030
    0.3070
    0.3200
    0.3250
    0.3390
    0.3950
    0.4560
    0.5250
    0.6120
    0.6220
    0.6350


samp =

    0.0660
    0.0750
    0.0820
    0.0900
    0.1130
    0.1150
    0.1200
    0.1250
    0.1290
    0.1330
    0.1440
    0.1630
    0.1760
    0.1820
    0.1930
    0.2220
    0.2320
    0.2750
    0.2770
    0.2890
    0.3460
    0.3700
    0.4190
    0.4280
    0.4510
    0.4760
    0.4800
    0.4830
    0.5010
    0.5330
    0.5360
    0.5410
    0.5470
    0.5550
    0.5600
    0.6190
    0.6270
    0.6320


samp =

    0.0080
    0.0120
    0.0190
    0.0630
    0.0660
    0.0710
    0.0730
    0.0760
    0.0860
    0.0970
    0.1010
    0.1100
    0.1230
    0.1250
    0.1450
    0.1520
    0.1570
    0.1830
    0.1970
    0.2080
    0.2730
    0.2810
    0.3320
    0.3440
    0.3610
    0.3660
    0.3730
    0.4650
    0.4700
    0.4760
    0.4830
    0.4950
    0.5380
    0.5410
    0.5450
    0.5530
    0.6240


samp =

    0.0110
    0.0310
    0.0460
    0.0720
    0.0780
    0.0840
    0.0940
    0.0980
    0.1160
    0.1250
    0.1520
    0.1550
    0.1620
    0.1740
    0.1960
    0.2120
    0.2460
    0.2660
    0.2730
    0.5110
    0.5180
    0.5290
    0.6190


samp =

    0.0260
    0.0380
    0.0480
    0.0750
    0.0790
    0.0820
    0.0870
    0.0900
    0.1040
    0.1150
    0.1250
    0.1340
    0.1360
    0.1600
    0.1660
    0.1760
    0.1840
    0.1920
    0.1970
    0.2060
    0.2280
    0.2350
    0.2430
    0.2490
    0.2770
    0.2850
    0.2910
    0.2970
    0.3290
    0.3340
    0.3660
    0.4270
    0.4300
    0.4430
    0.5170
    0.5220
    0.6040
    0.6120
    0.6500


samp =

    0.0090
    0.0120
    0.0240
    0.0270
    0.0380
    0.0410
    0.0530
    0.0630
    0.0670
    0.0770
    0.0810
    0.0870
    0.1010
    0.1100
    0.1150
    0.1330
    0.1460
    0.1530
    0.1620
    0.1650
    0.1690
    0.1810
    0.1890
    0.1920
    0.2340
    0.2370
    0.2470
    0.2770
    0.2800
    0.3000
    0.3420
    0.4120
    0.5150
    0.5200
    0.5760
    0.5840
    0.6060


samp =

    0.0220
    0.0300
    0.0660
    0.0820
    0.1160
    0.1210
    0.1390
    0.1530
    0.1670
    0.1810
    0.1870
    0.2010
    0.2060
    0.2370
    0.2530
    0.2580
    0.2660
    0.3000
    0.3220
    0.3360
    0.3670
    0.4930
    0.5570
    0.6340


samp =

    0.0050
    0.0500
    0.0830
    0.0950
    0.1000
    0.1080
    0.1160
    0.1190
    0.1270
    0.1440
    0.1540
    0.1620
    0.1700
    0.1840
    0.1900
    0.2110
    0.2300
    0.2510
    0.2640
    0.2850
    0.2940
    0.2970
    0.3130
    0.3270
    0.3400
    0.3540
    0.3740
    0.3950
    0.4140
    0.4350
    0.4780
    0.4820
    0.4880
    0.4980
    0.6330


samp =

    0.0240
    0.0710
    0.0770
    0.1100
    0.1130
    0.1160
    0.1240
    0.1330
    0.2030
    0.2050
    0.2090
    0.2220
    0.2570
    0.2600
    0.2760
    0.2790
    0.2870
    0.2900
    0.3460
    0.3520
    0.3620
    0.3930
    0.4840
    0.5520


samp =

    0.0340
    0.0380
    0.0410
    0.0540
    0.0740
    0.0770
    0.0870
    0.0970
    0.1010
    0.1100
    0.1280
    0.1340
    0.1380
    0.1490
    0.1550
    0.1660
    0.1760
    0.1810
    0.1950
    0.2470
    0.2520
    0.2580
    0.2620
    0.3500
    0.3580
    0.3910
    0.3960
    0.4100
    0.4300
    0.4400
    0.4430
    0.4950
    0.5820
    0.5850


samp =

    0.0140
    0.0190
    0.0690
    0.0720
    0.0760
    0.0820
    0.0880
    0.0950
    0.1130
    0.1180
    0.1250
    0.1300
    0.1360
    0.1420
    0.1620
    0.1640
    0.1710
    0.1730
    0.1870
    0.1890
    0.1920
    0.1970
    0.2100
    0.2150
    0.2230
    0.2300
    0.2350
    0.2440
    0.2470
    0.2500
    0.2530
    0.2570
    0.2640
    0.2680
    0.2720
    0.2760
    0.2800
    0.2850
    0.2950
    0.3090
    0.3110
    0.3170
    0.3310
    0.3360
    0.3430
    0.3480
    0.3550
    0.3880
    0.3910
    0.4040
    0.4130
    0.4380
    0.4550
    0.4620
    0.4670
    0.4750
    0.4840
    0.4960
    0.5070
    0.5110
    0.5330
    0.5470
    0.5550
    0.6120
    0.6180


samp =

    0.0210
    0.0270
    0.0310
    0.0570
    0.0770
    0.0790
    0.0840
    0.0910
    0.1010
    0.1150
    0.1220
    0.1430
    0.1490
    0.1560
    0.1620
    0.2060
    0.2080
    0.2170
    0.2290
    0.2440
    0.2760
    0.3050
    0.3080
    0.3290
    0.3500
    0.3750
    0.3820
    0.4210
    0.4550
    0.4680
    0.4700
    0.4760
    0.4820
    0.5670
    0.6080
    0.6380
    0.6440


samp =

    0.0160
    0.0200
    0.0250
    0.0410
    0.0460
    0.0970
    0.1040
    0.1070
    0.1110
    0.1170
    0.1240
    0.1430
    0.1560
    0.1620
    0.1710
    0.1770
    0.1820
    0.1930
    0.2020
    0.2430
    0.2470
    0.2520
    0.2540
    0.2930
    0.2980
    0.3160
    0.3200
    0.3220
    0.3280
    0.3360
    0.3480
    0.3900
    0.4330
    0.4460
    0.4500
    0.4980
    0.5850
    0.5900
    0.6170
    0.6350


samp =

    0.0030
    0.0080
    0.0150
    0.0210
    0.0620
    0.0690
    0.0760
    0.0790
    0.0930
    0.0960
    0.1010
    0.1090
    0.1220
    0.1260
    0.1410
    0.1570
    0.1610
    0.1650
    0.1730
    0.1870
    0.2090
    0.2210
    0.2280
    0.2330
    0.2470
    0.2670
    0.2730
    0.2780
    0.2800
    0.3080
    0.3180
    0.3230
    0.3310
    0.3360
    0.3520
    0.3550
    0.3690
    0.3740
    0.3820
    0.3970
    0.4430
    0.4450
    0.4570
    0.4660
    0.4830
    0.5350
    0.5510
    0.5570
    0.5650
    0.6110
    0.6170
    0.6220
    0.6280


samp =

    0.0040
    0.0100
    0.0140
    0.0260
    0.0450
    0.0590
    0.0740
    0.0800
    0.1000
    0.1100
    0.1160
    0.1200
    0.1290
    0.1440
    0.1630
    0.1670
    0.1690
    0.1740
    0.1760
    0.1930
    0.1970
    0.2010
    0.2100
    0.2280
    0.2340
    0.2470
    0.2930
    0.2960
    0.3510
    0.3540
    0.3650
    0.4430
    0.4530
    0.5000
    0.5140
    0.5400
    0.5840
    0.5910


samp =

    0.0280
    0.0340
    0.0380
    0.0520
    0.0610
    0.0710
    0.0750
    0.1150
    0.1180
    0.1240
    0.1280
    0.1310
    0.1370
    0.1430
    0.1480
    0.1520
    0.1880
    0.1980
    0.2460
    0.2490
    0.2560
    0.2650
    0.2980
    0.3110
    0.3170
    0.3270
    0.3560
    0.3680
    0.3780
    0.4100
    0.4120
    0.4170
    0.4760
    0.4850
    0.5050
    0.5800
    0.5890


samp =

         0
    0.0300
    0.0380
    0.0410
    0.0460
    0.0530
    0.0600
    0.0700
    0.0730
    0.0810
    0.0850
    0.1070
    0.1090
    0.1180
    0.1210
    0.1320
    0.1380
    0.1470
    0.1580
    0.1630
    0.1700
    0.1800
    0.1920
    0.2180
    0.2220
    0.2290
    0.2320
    0.2440
    0.2480
    0.2630
    0.2700
    0.2930
    0.2980
    0.3110
    0.3160
    0.3230
    0.3470
    0.3500
    0.3580
    0.3700
    0.3770
    0.4100
    0.4180
    0.4210
    0.4300
    0.4360
    0.4480
    0.4560
    0.4980
    0.5040
    0.5100
    0.5350
    0.6030
    0.6150
    0.6240
    0.6420


samp =

    0.0060
    0.0130
    0.0280
    0.0600
    0.0690
    0.0720
    0.0750
    0.0790
    0.0890
    0.0940
    0.1110
    0.1200
    0.1290
    0.1410
    0.1680
    0.1710
    0.1810
    0.2170
    0.2480
    0.2500
    0.2620
    0.3140
    0.3180
    0.3480
    0.3540
    0.3720
    0.3820
    0.4030
    0.4130
    0.4180
    0.4280
    0.4750
    0.4860
    0.5540


samp =

    0.0040
    0.0060
    0.0190
    0.0290
    0.0850
    0.0930
    0.1050
    0.1120
    0.1220
    0.1250
    0.1420
    0.1660
    0.1690
    0.1870
    0.1920
    0.2420
    0.2490
    0.2580
    0.2680
    0.3240
    0.3280
    0.3360
    0.3430
    0.3530
    0.3630
    0.3680
    0.3760
    0.3880
    0.4040
    0.4060
    0.4380
    0.4520
    0.4580
    0.4710
    0.4790
    0.5010
    0.5060
    0.5140
    0.5250
    0.5380
    0.5480
    0.5890


samp =

    0.0060
    0.0140
    0.0800
    0.0910
    0.1040
    0.1060
    0.1200
    0.1270
    0.1610
    0.1630
    0.1690
    0.1720
    0.2310
    0.2370
    0.2410
    0.2450
    0.2570
    0.2820
    0.3240
    0.3440
    0.3600
    0.3620
    0.3670
    0.3730
    0.3850
    0.3980
    0.4160
    0.4200
    0.4250
    0.4410
    0.4490
    0.5030
    0.5090
    0.5730
    0.6010
    0.6080
    0.6150


samp =

    0.0460
    0.0480
    0.0500
    0.0540
    0.0560
    0.0580
    0.0680
    0.0720
    0.0780
    0.0820
    0.1130
    0.1490
    0.1550
    0.2470
    0.2540
    0.2590
    0.2660
    0.3120
    0.3290
    0.4590
    0.4670
    0.5450
    0.5530
    0.6310
    0.6330
    0.6370


samp =

    0.0110
    0.0140
    0.0710
    0.0810
    0.0910
    0.1120
    0.1160
    0.1190
    0.1250
    0.1330
    0.1420
    0.1500
    0.1600
    0.1670
    0.1770
    0.1810
    0.1860
    0.1930
    0.2020
    0.2080
    0.2470
    0.2550
    0.2580
    0.2670
    0.2770
    0.2960
    0.3000
    0.3070
    0.3420
    0.3450
    0.3550
    0.3630
    0.3670
    0.3850
    0.3880
    0.3930
    0.4140
    0.4350
    0.4420
    0.4690
    0.4720
    0.5330
    0.5350
    0.5510
    0.5550
    0.5610
    0.6270


samp =

    0.0050
    0.0100
    0.0140
    0.0760
    0.0830
    0.0880
    0.1040
    0.1140
    0.1180
    0.1460
    0.1500
    0.1600
    0.2020
    0.2050
    0.2480
    0.2520
    0.2620
    0.2660
    0.2730
    0.2760
    0.2910
    0.3040
    0.3210
    0.3310
    0.4120
    0.4150
    0.5030
    0.5110
    0.5150
    0.5270
    0.5390
    0.5480
    0.5900
    0.5940
    0.5990
    0.6040
    0.6110
    0.6170
    0.6440


samp =

    0.0270
    0.0300
    0.0370
    0.0390
    0.0530
    0.0640
    0.0800
    0.0870
    0.1010
    0.1090
    0.1120
    0.1210
    0.1280
    0.1340
    0.1460
    0.1640
    0.2160
    0.2210
    0.2360
    0.2510
    0.2760
    0.2870
    0.3010
    0.3560
    0.3670
    0.4840
    0.5830
    0.6350
    0.6410


samp =

    0.0150
    0.0710
    0.0760
    0.0830
    0.1030
    0.1090
    0.1110
    0.1130
    0.1190
    0.1240
    0.1700
    0.1760
    0.1860
    0.1890
    0.1980
    0.2050
    0.2100
    0.2850
    0.2880
    0.3010
    0.3040
    0.3100
    0.3670
    0.3830
    0.4120
    0.4140
    0.4220
    0.4490
    0.4840
    0.5340
    0.6000
    0.6050


samp =

    0.0370
    0.0700
    0.1160
    0.1630
    0.1910
    0.2250
    0.3470
    0.3960
    0.4520
    0.4920
    0.5850
    0.6290


samp =

    0.2670
    0.4590
    0.5760


samp =

    0.0500
    0.5740
    0.6390


samp =

    0.4810


samp =

    0.1110
    0.3240
    0.5090
    0.5590


samp =

    0.1500
    0.3200


samp =

    0.3020
    0.3470
    0.4010
    0.4740
    0.5680


samp =

  0&times;1 empty double column vector


samp =

    0.0530
    0.2420
    0.4430
    0.5260


samp =

    0.0110
    0.3690
    0.4810
    0.6150


samp =

    0.1700
    0.3150


samp =

    0.2490
    0.4840
    0.5530
    0.5810
    0.6480


samp =

    0.1600
    0.2340


samp =

    0.0610
    0.1650
    0.2220
    0.4720
    0.5330
    0.5940
    0.6460


samp =

    0.0720


samp =

    0.5060
    0.5980


samp =

    0.1990
    0.2510


samp =

    0.2740
    0.4950
    0.5510
    0.5860
    0.6270


samp =

    0.1800
    0.2330
    0.3310
    0.3790
    0.5670
    0.5910
    0.6370


samp =

    0.0840
    0.1360


samp =

    0.1070
    0.1360
    0.2800
    0.5010


samp =

    0.5950


samp =

    0.1280
    0.5360


samp =

    0.0330
    0.1360
    0.5970


samp =

    0.0410
    0.1240
    0.2350
    0.2840
    0.5250
    0.5550
    0.5930


samp =

    0.0510
    0.0930
    0.1250
    0.2450
    0.4180
    0.5630


samp =

    0.0390
    0.2060
    0.3290
    0.4210
    0.4980
    0.5760


samp =

    0.1500
    0.2740
    0.3840
    0.4560


samp =

    0.0480
    0.1700
    0.2320
    0.4220
    0.4320
    0.4860
    0.6050
    0.6410


samp =

    0.0380
    0.1540
    0.2350
    0.3510
    0.5030
    0.5500
    0.5880


samp =

    0.5200


samp =

    0.1320
    0.2160
    0.3120
    0.4490


samp =

    0.0630
    0.0870
    0.1790
    0.2350
    0.2700
    0.3130
    0.6110


samp =

    0.0430
    0.3250
    0.4160
    0.4530
    0.5360
    0.5760
    0.6370


samp =

    0.3200
    0.6300


samp =

         0
    0.0430
    0.0850
    0.2830
    0.3310
    0.4650
    0.5060
    0.5360
    0.5620
    0.6030


samp =

    0.5100
    0.5730


samp =

    0.1690
    0.1960
    0.4410
    0.5070


samp =

    0.1300
    0.4820
    0.5790


samp =

    0.4740
    0.5180
    0.5690
    0.5940


samp =

    0.0330
    0.1590
    0.2470
    0.4570
    0.5010
    0.5760
    0.6190
    0.6470


samp =

    0.0470
    0.5770


samp =

    0.2030
    0.2450
    0.3390
    0.5750


samp =

    0.0750
    0.2170
    0.2960


samp =

    0.0390
    0.1080
    0.3390
    0.3910
    0.4540
    0.6110
    0.6440


samp =

    0.1740
    0.2690
    0.3160
    0.4570


samp =

    0.0470
    0.0770
    0.3150


samp =

    0.0560
    0.1040
    0.1600
    0.2780
    0.3070
    0.3410
    0.3940
    0.4580
    0.4830
    0.5120
    0.5390
    0.6440


samp =

    0.3330
    0.4300
    0.4610
    0.5000
    0.5310
    0.5540
    0.5930
    0.6430


samp =

    0.0560

</pre><h2 id="13">3.2b</h2><pre class="codeinput">fprintf(<span class="string">'The choice probabilities are: \n'</span>)
fprintf(<span class="string">'Neuron 1 \n'</span>)
fprintf(<span class="string">'Pretrial: %2.4f \n'</span>, p_1(1))
fprintf(<span class="string">'Sample: %2.4f \n'</span>, p_1(2))
fprintf(<span class="string">'Delay: %2.4f \n'</span>, p_1(3))
fprintf(<span class="string">'Test: %2.4f'</span>, p_1(4))
fprintf(<span class="string">'\n \n'</span>)
fprintf(<span class="string">'Neuron 2 \n'</span>)
fprintf(<span class="string">'Pretrial: %2.4f \n'</span>, p_2(1))
fprintf(<span class="string">'Sample: %2.4f \n'</span>, p_2(2))
fprintf(<span class="string">'Delay: %2.4f \n'</span>, p_2(3))
fprintf(<span class="string">'Test: %2.4f \n'</span>, p_2(4))

fprintf(<span class="string">'The choice probabilities in the pre-trial intervals are'</span>)
fprintf(<span class="string">' %2.4f and %2.4f \n'</span>, [p_1(1) p_2(1)])
fprintf(<span class="string">'This means that even among the ambiguous trials, the ones which'</span>)
fprintf(<span class="string">' were coded with a 1 had a different distribution than those\n'</span>)
fprintf(<span class="string">'that were coded with a 2\n'</span>)
fprintf(<span class="string">'In other words, the codings for ambiguous data were not randomly'</span>)
fprintf(<span class="string">'assigned'</span>)
</pre><pre class="codeoutput">The choice probabilities are: 
Neuron 1 
Pretrial: 0.3810 
Sample: 0.4040 
Delay: 0.5600 
Test: 0.5090
 
Neuron 2 
Pretrial: 0.4690 
Sample: 0.4910 
Delay: 0.6580 
Test: 0.6050 
The choice probabilities in the pre-trial intervals are 0.3810 and 0.4690 
This means that even among the ambiguous trials, the ones which were coded with a 1 had a different distribution than those
that were coded with a 2
In other words, the codings for ambiguous data were not randomlyassigned</pre><p class="footer"><br><a href="http://www.mathworks.com/products/matlab/">Published with MATLAB&reg; R2017b</a><br></p></div><!--
##### SOURCE BEGIN #####

load('mtSpikeTimes.mat');

%% 1.1 & 1.2

figure; hold on
subplot(8,1,[1 2])
for i = 1:length(mtSpikeTimes)
    trial = mtSpikeTimes{i};
    
    for iid = 1:length(trial)
        hold on
        spkx=[trial(iid) trial(iid)];
        spky = [0 1] + i;
        line(spkx,spky,'LineWidth',1);
    end
end
xlabel('Time (sec)')
title('Raster Plot')

subplot(8,1,[4 5])
PlotPSTH(mtSpikeTimes, 10)
title('PSTH 10 bins')

subplot(8,1,[7 8])
PlotPSTH(mtSpikeTimes, 20)
title('PSTH 20 bins')

fprintf('As the number of bins increases, the "resolution" on the graph')
fprintf(' gets finer, which may mean the curve gets smoother if you start \n')
fprintf(' with too few bins, but may mean it gets more jagged if you go too')
fprintf(' high.')

%% 2.1


[mean_val, std_val, coef_var, fano, d] = GetStats(mtSpikeTimes, .03);
fprintf('For 30ms: \n')
fprintf('The mean firing rate is %4.5f \n', mean_val)
fprintf('The standard deviation of the firing rate is %4.5f \n', std_val)
fprintf('The coefficient of variation is %4.5f \n', coef_var)
fprintf('The Fano Factor of the counts is: %4.5f \n', fano)

clear mean_val std_val coef_var fano d

[mean_val, std_val, coef_var, fano, d] = GetStats(mtSpikeTimes, .3);
fprintf('For 300ms: \n')
fprintf('The mean firing rate is %4.5f \n', mean_val)
fprintf('The standard deviation of the firing rate is %4.5f \n', std_val)
fprintf('The coefficient of variation is %4.5f \n', coef_var)
fprintf('The Fano Factor of the counts is: %4.5f \n', fano)





%% 2.2
% ISI histogram
figure; hold on 

%normalize histogram
[nums, cents] = hist(d, 100);
nums = nums / nums(1);
bar(cents, nums);


% fit exponential curve
x = linspace(0, .5, 100);
y = exp((-x)*mean_val);
plot(x,y, 'color', 'red');

fprintf('The curves match fairly well, the histogram appears to be')
fprintf(' following the exponential curve I added to the graph to ')
fprintf(' illustrate a Poisson distribution.')


%% 

load('S1_Ideal_Observer_Analysis.mat');


%% 3.1a


% preparing the data
amplitudes = Data.stimuli{1}(:,2,:);
directions = Data.stimuli{1}(:,3,:);

new_directions = [];
neuron_1 = {};
neuron_2 = {};
for i = 1:length(Data.spikes{1})
    if amplitudes(i) == 700
        neuron_1{length(neuron_1) + 1} = Data.spikes{1}{i};
        neuron_2{length(neuron_2) + 1} = Data.spikes{2}{i};
        new_directions = [new_directions directions(i)];
    end
end

% make a colormap
colormap = GetColormap(directions)



figure; hold on


subplot(1,2,1)
RasterByDirection(new_directions, neuron_1, colormap)
title('Neuron 1');


subplot(1,2,2)
RasterByDirection(new_directions, neuron_2, colormap)
title('Neuron 2');



%% 3.1b


figure; hold on

% sort trials by direction

trial_by_direction_1 = SortTrialsByDirection(new_directions, neuron_1);
trial_by_direction_2 = SortTrialsByDirection(new_directions, neuron_2);

% now get the avg firing rates for each direction

% now plot and get the preferred direction and firing rates sorted
% by direction
subplot(2,1,1)
[preferred_1, rates_by_direction_1] = ...
    GetFiringRatesAndAvg(trial_by_direction_1);
title('Neuron 1')

subplot(2,1,2)
[preferred_2, rates_by_direction_2] = ...
    GetFiringRatesAndAvg(trial_by_direction_2);
title('Neuron 2')



%% 3.1c
figure; hold on

subplot(2,1,1)
threshold_1 = PlotNeurometric(rates_by_direction_1, preferred_1, 1000)
title('Neuron 1');

subplot(2,1,2)
threshold_2 = PlotNeurometric(rates_by_direction_2, preferred_2, 1000)
title('Neuron 2')


fprintf('The threshold for both is around 22.5 \n')
fprintf('The second neuron is abnormal because it dips significantly')
fprintf(' below the threshold after it reaches it')

%% 3.1d

[preferred_1, new_rates_1] = ResortByDirection(rates_by_direction_1);
[preferred_2, new_rates_2] = ResortByDirection(rates_by_direction_2);

figure; hold on

subplot(2,1,1)
threshold_1 = PlotNeurometric(new_rates_1, preferred_1, 10000)

subplot(2,1,2)
threshold_2 = PlotNeurometric(new_rates_2, preferred_2, 10000)

fprintf('The thresholds are: \n')
fprintf('Neuron 1: %2.1f \n', threshold_1)
fprintf('Neuron 2: %2.4f \n', threshold_2)


%% 3.2
load('choiceData.mat')


%% 3.2a

behaviors_1 = choiceData.behavioralReport{1};
behaviors_2 = choiceData.behavioralReport{2};
neuron_1 = choiceData.spikes{1};
neuron_2 = choiceData.spikes{2};

figure;hold on

RasterByBehavior(neuron_1, behaviors_1, 1)
title('Neuron 1/ Behavior 1')

figure; hold on
RasterByBehavior(neuron_1, behaviors_1, 2)
title('Neuron 1/ Behavior 2')

figure; hold on 
RasterByBehavior(neuron_2, behaviors_2, 1)
title('Neuron 2/ Behavior 1')

figure; hold on
RasterByBehavior(neuron_2, behaviors_2, 2)
title('Neuron 2/ Behavior 2')


%% 3.2b

p_1 = ChoiceProbabilities(neuron_1, behaviors_1, 1000);
p_2 = ChoiceProbabilities(neuron_2, behaviors_2, 1000);


%% 3.2b
fprintf('The choice probabilities are: \n')
fprintf('Neuron 1 \n')
fprintf('Pretrial: %2.4f \n', p_1(1)) 
fprintf('Sample: %2.4f \n', p_1(2))
fprintf('Delay: %2.4f \n', p_1(3))
fprintf('Test: %2.4f', p_1(4))
fprintf('\n \n')
fprintf('Neuron 2 \n')
fprintf('Pretrial: %2.4f \n', p_2(1)) 
fprintf('Sample: %2.4f \n', p_2(2))
fprintf('Delay: %2.4f \n', p_2(3))
fprintf('Test: %2.4f \n', p_2(4))

fprintf('The choice probabilities in the pre-trial intervals are')
fprintf(' %2.4f and %2.4f \n', [p_1(1) p_2(1)])
fprintf('This means that even among the ambiguous trials, the ones which')
fprintf(' were coded with a 1 had a different distribution than those\n')
fprintf('that were coded with a 2\n')
fprintf('In other words, the codings for ambiguous data were not randomly')
fprintf('assigned')










##### SOURCE END #####
--></body></html>